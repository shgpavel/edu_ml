## run
```
  python -m venv .
  ./bin/pip install -r requirements.txt
  ./bin/python main.py
```

## q&a
  q: Значение параметра n_init в тексте не указано. Требуется подобрать минимальное значение n_init, при котором итоговое SSE становится стабильным (больше не меняется при росте n_init) и минимальным, а число итераций до сходимости остаётся небольшим. Провести сравнение с другими значениями n_init (меньше/больше найденного).

  a: При маленьком n_init SSE завышен (условно при 5 не 69к, а 71к), при увеличении падает, где-то с 10  в целом перестает падать. При например n_init=40
  получаем более низкий SSE 69400 vs 69600 (у 10), но осатльные метрики ухудшаются

  q: Какая реализация показывает себя по метрикам как наилучшая? Наблюдаются ли случаи, когда одно значение метрики лучше, а другое хуже? Что это говорит о многогранности оценки качества кластеризации и о необходимости анализа всех метрик вместе, а не по одной?

  a: Классические метрики дали преимущество самописной версии, у нее ниже SSE, DB и чуть лучше разделяет точки (Silhouette).
  Чистота тоже выше ~71% против ~68%. Видимого переобучения нет, кластеры плотнее и ближе к истинным цифрам одновременно.
  Разброс расстояний до центров гистограммы у обеих моделей похож: короткий острый пик и длинный правый хвост ~ 45. Хвосты скорее всего редкие
  не-типичные изображения цифр.

  q: Какое значение чистоты получилось у нашей реализации, а какое — у sklearn? Если разница в чистоте небольшая (например, несколько процентов), о чём это может говорить? Можно ли сказать, что обе реализации работают достаточно хорошо? Если чистота кластеров очень высокая, всегда ли это гарантирует, что кластеры полностью правильно отражают структуру данных и что это говорит о важности данной метрики?

  a: 0.71 у нас и 0.68 у sklearn, значит, что собственная инициализация при n_init = 10 подобрала более удачные центры. Однако чистота -- односторонний индикатор: она не штрафует за слияние классов, поэтому её надо проверять вместе с внутрикластерной плотностью и межкластерными расстояниями.

  q: Видны ли на графиках компактные группы точек одного цвета? Что это может говорить о качестве кластеризации? Есть ли места, где цвета кластеров сильно перемешаны, и как интерпретировать наличие смешанных областей? Есть ли заметные выбросы — одиночные точки вдали от основных кластеров: что это может говорить о сложности задачи или неправильном числе кластеров?

  a: Чёткие, хорошо отделённые облака одного цвета -- цифры 0, 1, 6. Области смешения цветов -- сочетания 3/5, 4/9, 7/9, т. к. эти цифры визуально похожи.
  Несколько одиночных выбросов вдали от плотных групп -- шумные или плохо написанные символы.

  q: У кого гистограмма острее, а расстояния до центров меньше? Что это показывает о компактности построенных кластеров? Есть ли длинные хвосты на гистограммах? Что наличие длинных хвостов может сказать о наличии шумов или выбросов в данных? Наблюдаются ли явные отличия в распределении расстояний между двумя реализациями? О чём это может свидетельствовать относительно качества разбиения?

  a: У обеих моделей высокий узкий пик около 5 и длинный правый хвост вплоть до ~ 45. Острее пик у custom-версии, чуть больше точек лежат ближе к центрам.

  q: Может ли способ выбора начальных центров кластеров влиять на итоговую чистоту и плотность кластеров? Если начальные центры выбираются случайно, могут ли они попасть в неудобные места и ухудшить разбиение? И что бы изменилось, если бы начальные центры подбирались более «осознанно», исходя из структуры данных?

  a: Случайный выбор в неудачные позиции даёт заведомо худшее SSE и может расколоть очевидный класс или, наоборот, слить разные.
